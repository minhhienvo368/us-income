{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca474114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px \n",
    "\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "#Data analysing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Classification models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.naive_bayes import  GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23626e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data_train.csv\")\n",
    "df_test = pd.read_csv(\"data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f9d3464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>257302</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>154374</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>151910</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>201490</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>287927</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  fnlwgt  education  education-num  marital-status  \\\n",
       "32556   27          2  257302          6             12               1   \n",
       "32557   40          2  154374          1              9               1   \n",
       "32558   58          2  151910          1              9               6   \n",
       "32559   22          2  201490          1              9               0   \n",
       "32560   52          6  287927          1              9               1   \n",
       "\n",
       "       occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
       "32556          10             2     0    1             0             0   \n",
       "32557           9             1     0    0             0             0   \n",
       "32558           0             4     0    1             0             0   \n",
       "32559           0             3     0    0             0             0   \n",
       "32560           1             2     0    1         15024             0   \n",
       "\n",
       "       hours-per-week  native-country  income  \n",
       "32556              38               0       0  \n",
       "32557              40               0       1  \n",
       "32558              40               0       0  \n",
       "32559              20               0       0  \n",
       "32560              40               0       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns',111)\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "238f2046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    37155\n",
      "1    11687\n",
      "Name: income, dtype: int64\n",
      "0    24720\n",
      "1     7841\n",
      "Name: income, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "print(df['income'].value_counts())\n",
    "print(df_train['income'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "884a2c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "education-num     0\n",
       "marital-status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital-gain      0\n",
       "capital-loss      0\n",
       "hours-per-week    0\n",
       "native-country    0\n",
       "income            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a488b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the redundant columns\n",
    "df = df.drop('education-num', axis=1)\n",
    "df_train = df_train.drop('education-num', axis=1)\n",
    "df_test = df_test.drop('education-num', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3362db60",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Separating categorical and continuous variables\n",
    "#{cat: <45, cont:>45}\n",
    "cat=[feature for feature in df.columns if df[feature].nunique()<45]\n",
    "cont=[feature for feature in df.columns if df[feature].nunique()>45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a779ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48842, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat = df[cat].copy()\n",
    "df_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7cbce66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48842, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cont = df[cont].copy()\n",
    "df_cont.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3111d74c",
   "metadata": {},
   "source": [
    "## Implementation: Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045921da",
   "metadata": {},
   "source": [
    "As we can see that the last column from this dataset, 'income', will be our target label (whether an individual makes more than, or at most, $50,000 annually). All other columns are features about each individual in the census database.\n",
    "\n",
    "A premilinary investigation of the dataset will determine how many individuals fit into either group, and will tell us about the percentage of these individuals making more than \\$50,000. In the code cell below, you will need to compute the following:\n",
    "\n",
    "- The total number of records, 'n_records'\n",
    "- The number of individuals making more than \\$50,000 annually, 'n_greater_50k'.\n",
    "- The number of individuals making at most \\$50,000 annually, 'n_at_most_50k'.\n",
    "- The percentage of individuals making more than \\$50,000 annually, 'greater_percent'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2b8be0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 48842\n",
      "Individuals making more than $50,000: 11687\n",
      "Individuals making at most $50,000: 37155\n",
      "Percentage of individuals making more than $50,000: 23.93%\n"
     ]
    }
   ],
   "source": [
    "# DONE: Total number of records\n",
    "n_records = df['income'].count()\n",
    "\n",
    "# DONE: Number of records where individual's income is more than $50,000\n",
    "count = 0\n",
    "count = [count+1 for income in df['income'] if income == 1]\n",
    "n_greater_50k = sum(count)\n",
    " \n",
    "# DONE: Number of records where individual's income is at most $50,000\n",
    "n_at_most_50k = n_records - n_greater_50k\n",
    "\n",
    "# DONE: Percentage of individuals whose income is more than $50,000\n",
    "greater_percent = (n_greater_50k*100.0)/n_records\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of records: {}\".format(n_records)) \n",
    "print(\"Individuals making more than $50,000: {}\".format(n_greater_50k)) \n",
    "print(\"Individuals making at most $50,000: {}\".format(n_at_most_50k)) \n",
    "print(\"Percentage of individuals making more than $50,000: {:.2f}%\".format(greater_percent)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d3033c",
   "metadata": {},
   "source": [
    "#### Take the combined dataframe and split it into train, validation and test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3c1a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option2: Run for all dataset (categorical and continuous data) without Validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=df.copy()\n",
    "X.drop('income',axis=1,inplace=True)\n",
    "y=df['income']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76eacac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply with X_train < X_train_val\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "ran_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "ran_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = ran_forest.predict(X_test)\n",
    "\n",
    "#for name, score in zip(df.columns, ran_forest.feature_importances_):\n",
    "#    print(name, score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d0f7e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on the training set yields an accuracy of 99.9872034397154%\n",
      "Evaluating the model on the testing set yields an accuracy of 85.81%\n"
     ]
    }
   ],
   "source": [
    "score = ran_forest.score(X_train, y_train)\n",
    "print(\"Evaluating the model on the training set yields an accuracy of {}%\".format(score*100))\n",
    "score=ran_forest.score(X_test, y_test)\n",
    "print(\"Evaluating the model on the testing set yields an accuracy of {:.2f}%\".format(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94900d66",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fbeta_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c72cce2c0c6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#print clf.get_params().keys()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# DONE: Make an fbeta_score scoring object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfbeta_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# DONE: Perform grid search on the classifier using 'scorer' as the scoring method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fbeta_score' is not defined"
     ]
    }
   ],
   "source": [
    "# DONE: Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# DONE: Initialize the classifier\n",
    "clf = RandomForestClassifier(random_state = 50)\n",
    "\n",
    "# Done: Create the parameters list you wish to tune\n",
    "parameters = {'min_samples_split' : [2,3,4,5],'min_samples_leaf' : [1,5,10,50,100,200,500] , 'n_jobs' : [1,-1]}\n",
    "\n",
    "#print clf.get_params().keys()\n",
    "# DONE: Make an fbeta_score scoring object\n",
    "scorer = make_scorer(fbeta_score, beta=.5,average='micro')\n",
    "\n",
    "# DONE: Perform grid search on the classifier using 'scorer' as the scoring method\n",
    "grid_obj = GridSearchCV(clf, parameters,scoring=scorer)\n",
    "\n",
    "# DONE: Fit the grid search object to the training data and find the optimal parameters\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train, y_train)).predict(X_test)\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions))) \n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5,average='micro'))) \n",
    "print(\"\\nOptimized Model\\n------\") \n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions))) \n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5,average='micro'))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ce5747",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4bae602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on the testing set yields an accuracy of 81.92% with random state 0\n",
      "Evaluating the model on the testing set yields an accuracy of 81.21% with random state 1\n",
      "Evaluating the model on the testing set yields an accuracy of 80.73% with random state 2\n",
      "Evaluating the model on the testing set yields an accuracy of 80.95% with random state 3\n"
     ]
    }
   ],
   "source": [
    "# Repeat the actions above for different random states\n",
    "for random_state in range(4):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=random_state, test_size=0.2)\n",
    "    classifier = DecisionTreeClassifier(random_state=1)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    score=classifier.score(X_test, y_test)\n",
    "    print(\"Evaluating the model on the testing set yields an accuracy of {:.2f}% with random state {}\".format(score*100, random_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01cc2146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on the training set yields an accuracy of 99.99232206382925%\n",
      "Evaluating the model on the testing set yields an accuracy of 80.95%\n"
     ]
    }
   ],
   "source": [
    "score = classifier.score(X_train, y_train)\n",
    "print(\"Evaluating the model on the training set yields an accuracy of {}%\".format(score*100))\n",
    "score=classifier.score(X_test, y_test)\n",
    "print(\"Evaluating the model on the testing set yields an accuracy of {:.2f}%\".format(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c2e443d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81021599 0.81318456 0.81900082 0.81214169 0.80773956]\n",
      "Accuracy: 81.25% (+/- 0.38)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "classifier = DecisionTreeClassifier(random_state=1)\n",
    "scores = cross_val_score(classifier, X, y, cv=5) # cv is the number of folds (k)\n",
    "print(scores)\n",
    "\n",
    "# It is always a good practice to show the mean AND the standard deviation of the model accuracy\n",
    "print(\"Accuracy: {:.2f}% (+/- {:.2f})\".format(scores.mean() * 100, scores.std() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cdd639",
   "metadata": {},
   "source": [
    "### Finding the best hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0ab3447",
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'n_estimators':[100,300,500],\n",
    "            'criterion':['gini','entropy'],\n",
    "            'max_depth':[None,1,2,3,4,5],\n",
    "           'max_features':['int','float','auto','log2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a20b2d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=41, test_size=0.2)\n",
    "ran_forest = RandomForestClassifier(random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0d7d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the grid search that will test every combination of parameters\n",
    "gridsearch = GridSearchCV(RandomForestClassifier(),params,cv=10\n",
    "\n",
    "# As we are doing cross-validation on the training set, the testing set X_test is untouched\n",
    "result = gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06823c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best parameters are :\", result.best_params_)\n",
    "print(\"The best accuracy is {:.2f}%:\".format(result.best_score_ * 100))\n",
    "\n",
    "# We can now use the testing set with the optimal hyper-parameters to get the final generalization accuracy\n",
    "ran_forest = result.best_estimator_\n",
    "score = ran_forest.score(X_test, y_test)\n",
    "print(\"The generalization accuracy of the model is {:.2f}%\".format(score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a762f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_grid_search(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Performs a grid search using the training set given.\n",
    "    \"\"\"\n",
    "    # Setting all the parameters we want to test\n",
    "    params = {\n",
    "        'max_features' : np.arange(0.1,1,0.1).tolist(), #Number of features to consider as a fraction of all features\n",
    "        'max_depth': [1,2,4,8, None] # Depth of the tree\n",
    "    }\n",
    "\n",
    "    gridsearch = GridSearchCV(estimator = ran_forest,\n",
    "                            param_grid = params,\n",
    "                            scoring = 'accuracy', \n",
    "                            cv = 5, # Use 5 folds\n",
    "                            verbose = 0,\n",
    "                            n_jobs = -1 #Use all but one CPU core\n",
    "                            )\n",
    "\n",
    "    # As we are doing cross-validation on the training set, the testing set X_test is untouched    \n",
    "    return gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5823a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redoing the same computation as before, but this time\n",
    "# using the method we created to show that we have the same results\n",
    "result = single_grid_search(X_train, y_train)\n",
    "ran_forest = result.best_estimator_\n",
    "score = ran_forest.score(X_test, y_test)\n",
    "print(\"The generalization accuracy of the model is {:.2f}%\".format(score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f815d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECT MODEL\n",
    "\n",
    "# Now we can create k train-test splits using KFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Using KFold instead of calling multiple times train_test_split to ensure that each\n",
    "# sample goes into a single split only\n",
    "kf = KFold(n_splits=5, random_state=45, shuffle=True)\n",
    "\n",
    "split = 0\n",
    "scores = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    result = single_grid_search(X_train, y_train)\n",
    "    \n",
    "    decision_tree = result.best_estimator_\n",
    "    score = decision_tree.score(X_test, y_test)\n",
    "    scores.append(score)\n",
    "    print(\"### Split {}: Accuracy is {:.2f}% ###\".format(split := split + 1, score*100))\n",
    "    \n",
    "print(\"The mean generalization accuracy of the model is {:.2f}% (+/- {:.2f}%)\".format(np.mean(scores) * 100, np.std(scores) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f817bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3fbcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "####TRY THIS WHEN HAVE TIME££££"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd772e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dde3b6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find the best random state\n",
    "def random_state(X_int,y_int):\n",
    "    maxi=0\n",
    "    model=RandomForestClassifier()\n",
    "    for ran_st in range(1,201):\n",
    "        xtrain, xtest, ytrain, ytest=train_test_split(X_int, y_int, test_size=0.20, random_state=ran_st)\n",
    "        model.fit(xtrain,ytrain)\n",
    "        p=model.predict(xtest)\n",
    "        accu=accuracy_score(p,ytest)\n",
    "        if accu > maxi:\n",
    "            maxi = accu\n",
    "            ran_st2=ran_st\n",
    "    return ran_st2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1984eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To evakuate performances of all the models\n",
    "def performance(p,ytest,m,xtest,s):\n",
    "    print('------',m,'------------------------------------')\n",
    "    print('Accuracy',np.round(accuracy_score(p,ytest),4))\n",
    "    print('--------------')\n",
    "    print('Mean of Cross Validation Score',np.round(s.mean(),4))\n",
    "    print('--------------')\n",
    "    print('AUC_ROC Score',np.round(roc_auc_score(ytest,m.predict_proba(xtest)[:,1]),4))\n",
    "    print('--------------')\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(p,ytest))\n",
    "    print('--------------')\n",
    "    print('Classification Report')\n",
    "    print(classification_report(p,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "647970fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list of models which will be created one by one\n",
    "models=[#GaussianNB(),KNeighborsClassifier(),\n",
    "        #LogisticRegression(),DecisionTreeClassifier(),\n",
    "        RandomForestClassifier(),#AdaBoostClassifier(),\n",
    "        GradientBoostingClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7be828a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X_int,y_int):\n",
    "    xtrain,xtest,ytrain,ytest=train_test_split(X_int,y_int,test_size=0.2,random_state=randomstate(X_int,X_int))\n",
    "    for i in models:\n",
    "        model=i\n",
    "        model.fit(xtrain,ytrain)\n",
    "        p=model.predict(xtest)\n",
    "        score=cross_val_score(model,X_int,X_int,cv=10)\n",
    "        performance(p,ytest,model,xtest,score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a92733",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b69038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b3b17e2",
   "metadata": {},
   "source": [
    "### Listing of attributes:\n",
    "\n",
    "Target: income: >50K, <=50K.\n",
    "\n",
    " - age: continuous.\n",
    " - workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    " - fnlwgt (final weight): continuous.\n",
    " - education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    " - education-num: continuous.\n",
    " - marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    " - occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    " - relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    " - race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    " - sex: Female, Male.\n",
    " - capital-gain: continuous.\n",
    " - capital-loss: continuous.\n",
    " - hours-per-week: continuous.\n",
    " - native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faabfe5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
